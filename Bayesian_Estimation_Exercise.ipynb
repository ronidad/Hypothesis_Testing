{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Programming: Bayesian Estimation Exercise",
      "provenance": [],
      "collapsed_sections": [
        "-J3rsf11HoWc",
        "PxQym5lRPMqK"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8LCREF0SX58"
      },
      "source": [
        "<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5MVHbQjHkD0"
      },
      "source": [
        "# Python Programming: Bayesian Estimation Exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J3rsf11HoWc"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K49hiWLkHfIZ"
      },
      "source": [
        "# Example 1\n",
        "# ---\n",
        "# Determine the bias of a Thumbtack \n",
        "# (A thumbtack is a short flat-headed pin, used for fastening paper to a wall or other surface.)\n",
        "# ---\n",
        "# \n",
        "\n",
        "# We shall use the excellent PyMC library. Let's install it\n",
        "# We shall avoid going into the finer details of PyMC. Excellent documentation for PyMC \n",
        "# can be found both in the PyMC docs as well as the book \"Probabilistic Programming and Bayesian methods for Hackers\" \n",
        "# by Cam Davidson-Pilon's, which can be found online at \n",
        "# http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/.\n",
        "!pip install pymc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwpv2x0AIagZ"
      },
      "source": [
        "# For estimating theta, we shall first generate 30 samples from the Bernoulli distribution, \n",
        "# where the controlling parameter has a value of 0.3 \n",
        "# (which would correspond to roughly 30% of the generated values being 1, and the rest being 0).\n",
        "\n",
        "# Importing the libraries we will need\n",
        "from pymc import *\n",
        "from scipy.stats import bernoulli\n",
        "import matplotlib.pyplot as plt\n",
        "import pymc.Matplot as plott\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8STzJ76IuJh"
      },
      "source": [
        "# We attempt to find the parameters of the posterior distribution, and we've learnt that the posterior depends on the prior, as well the data. \n",
        "# There are many choices of prior available to us, in this case we shall use the uniform prior. \n",
        "# Since we have little idea about the bias of the thumbtack, we believe it can lie anywhere between 0 and 1.\n",
        "# The PyMC model contains two variables. The first is a Uniform prior, which represents our belief \n",
        "# that the value of the parameter can be anywhere between 0 and 1. \n",
        "# The second is the Bernoulli variable, to which we provide data. The two variables are linked in a parent-child relationship, \n",
        "# the Uniform prior is the designated parent of the Bernoulli variable.\n",
        "# We use two types of PyMC variables: Stochastic (the uni_prior variable, which can take different values based on the parameter theta). \n",
        "# Deterministic (such as 'bern', whose values are decided by its parents). Finally, all the variables in the model are wrapped in a Model object.\n",
        "# For all variables where observed is not True, PyMC's simulations will tickle the value of the variable during the simulation \n",
        "# and the value (of uni_prior in our case) will start to approximate its posterior values.\n",
        "\n",
        "from pymc import *\n",
        "from scipy.stats import bernoulli\n",
        "import matplotlib.pyplot as plt\n",
        "import pymc.Matplot as plott\n",
        "\n",
        "# Samples drawn from the prior distribution show that the prior is uniformly distributed between 0 and 1 on the x axis.\n",
        "def create_model(data):\n",
        "    #create a uniform prior, the lower and upper limits of which are 0 and 1\n",
        "    uni_prior = Uniform('uni_prior', lower=0,upper=1.0 )\n",
        "    bern = Bernoulli('bern',p=uni_prior, value=data,observed=True)\n",
        "    model=Model([uni_prior,bern])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3CxgzS5JCPL"
      },
      "source": [
        "# We now use a sampling method called Markov Chain Monte Carlo (hence the acronym MCMC). \n",
        "# MCMC is one of the methods used to draw samples from the posterior distribution. \n",
        "# We draw 5k samples, and draw a histogram of the samples (called traces in MCMC parlance).\n",
        "# In Bayesian statistics, the parameter theta is represented as a random variable and not a single value.\n",
        "\n",
        "sample_size=30\n",
        "\n",
        "def get_traces(sample_size):\n",
        "    data=bernoulli.rvs(0.3,size=sample_size)\n",
        "    model=create_model(data)\n",
        "    model.seed()\n",
        "    mc1 = MCMC(model)\n",
        "    mc1.sample(iter=5000,burn=1000)\n",
        "    return mc1,mc1.trace('uni_prior')[:]\n",
        "\n",
        "mc1,traces=get_traces(sample_size)\n",
        "plott.histogram(traces,\"uni_prior\")\n",
        "\n",
        "\n",
        "# We plot the posterior distribution of the parameter theta. We can see that the distribution has quite a bit of variance, \n",
        "# and the peak of the distribution (indicated by a black vertical line) \n",
        "# does not correspond to 0.3 (which is the true value of the parameter theta). \n",
        "# The peak of the distribution hill is called a point estimate in Bayesian parlance, \n",
        "# which is analogous to the \"best estimate\" if we want to represent the parameter theta as a single value."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k60gk5owJii3"
      },
      "source": [
        "# We then plot the posterior distribution for an increasing number of samples.\n",
        "num_samples=[20,50,100,500,5000]\n",
        "for i in num_samples:\n",
        "    m,traces=get_traces(i)\n",
        "    plott.histogram(traces,\"num samples = \"+str(i),datarange=(0,0.6))\n",
        "    \n",
        "# We can see that increasing the number of samples makes the distribution \"hill\" sharper, \n",
        "# which indicates its growing confidence in its estimate of the parameter theta."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmIRumIeKEjO"
      },
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# I tossed my coin 30  times, and it came up as heads  11  times. Is it biased?\n",
        "# ---\n",
        "# \n",
        "\n",
        "# Parameterized problem:\n",
        "#\n",
        "# \"I want to know  p , the probability of tossing heads. Given  n  tosses and  h  observed heads, \n",
        "# is it probable that the value of  p  is close to  0.5  , say, in the interval  [0.48,0.52] ?\"\n",
        "\n",
        "# Prior:\n",
        "# prior belief about parameter:  p∼Uniform(0,1) \n",
        "# likelihood function:  data∼Bernoulli(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2QM-QOLKyU8"
      },
      "source": [
        "# Make the data needed for the problem.\n",
        "from random import shuffle\n",
        "total = 30\n",
        "n_heads = 11\n",
        "n_tails = total - n_heads\n",
        "tosses = [1] * n_heads + [0] * n_tails\n",
        "shuffle(tosses)\n",
        "\n",
        "# printing out data\n",
        "print(tosses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dUGmGHlLJcl"
      },
      "source": [
        "# Creating a function to plot our tosses\n",
        "def plot_coins():\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.bar(list(Counter(tosses).keys()), list(Counter(tosses).values()))\n",
        "    ax.set_xticks([0, 1])\n",
        "    ax.set_xticklabels(['tails', 'heads'])\n",
        "    ax.set_ylim(0, 20)\n",
        "    ax.set_yticks(np.arange(0, 21, 5))\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxFbx_d9LRVZ"
      },
      "source": [
        "# Plotting\n",
        "fig = plot_coins()\n",
        "plt.show()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlJ3Gl10LZDe"
      },
      "source": [
        "# Context manager syntax. `coin_model` is **just** \n",
        "# a placeholder\n",
        "# \n",
        "with pm.Model() as coin_model: \n",
        "    # Distributions are PyMC3 objects.\n",
        "    # Specify prior using Uniform object.\n",
        "    p_prior = pm.Uniform('p', 0, 1)  \n",
        "    \n",
        "    # Specify likelihood using Bernoulli object.\n",
        "    like = pm.Bernoulli('likelihood', p=p_prior, \n",
        "                        observed=tosses)  \n",
        "                        # \"observed=data\" is key\n",
        "                        # for likelihood."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4t5ITtzLZ0j"
      },
      "source": [
        "# Writing our model in PyMC3, hitting the MCMC Inference Button (TM)\n",
        "# \n",
        "with coin_model:\n",
        "    # don't worry about this:\n",
        "    step = pm.Metropolis()\n",
        "    \n",
        "    # focus on this, the Inference Button:\n",
        "    coin_trace = pm.sample(2000, step=step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsUsq_fOLiQd"
      },
      "source": [
        "# Results\n",
        "# \n",
        "pm.traceplot(coin_trace)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgXHtntLLl3Q"
      },
      "source": [
        "# Interpreting based on posterior distributions\n",
        "# \n",
        "pm.plot_posterior(coin_trace[100:], color='#87ceeb', \n",
        "                  rope=[0.48, 0.52], point_estimate='mean', \n",
        "                  ref_val=0.5)\n",
        "plt.show()\n",
        "\n",
        "# 95% highest posterior density (HPD) encompasses the region of practical equivalence (ROPE) \n",
        "# thus we need to get more data. For more info (http://bit.ly/HPDandROPE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxQym5lRPMqK"
      },
      "source": [
        "## <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptXS0oISPSuY"
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# I tossed my coin 50  times, and it came up as tails 29  times. Is it biased?\n",
        "# --\n",
        "# \n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlSieDF-RvNj"
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Assume that we run an website for selling safari shoes and in order to bring people to our site, \n",
        "# we deploy several digital marketing campaigns. \n",
        "# These campaigns feature various ad images and captions, and are presented on a number of social networking websites. \n",
        "# We want to present the ads that are the most successful. \n",
        "# For the sake of simplicity, we can assume that the most successful campaign \n",
        "# is the one that results in the highest click-through rate: the ads that are most likely to be clicked if shown.\n",
        "# We introduce a new campaign called \"facebook-yellow-dress,\" a campaign presented to Facebook users featuring a yellow dress. \n",
        "# The ad has been presented to 10 users so far, and 7 of the users have clicked on it. \n",
        "# Determine the probability that the next user will click on the ad.\n",
        "# --\n",
        "OUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}